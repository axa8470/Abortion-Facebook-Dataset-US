"Analyzing the Stance of Facebook Posts on Abortion Considering
State-level Health and Social Compositions" Datasheet

Questions:
1. For what purpose was the dataset created?
The dataset has been created for the research project "Analyzing the Stance of Facebook Posts on Abortion Considering State-level Health and Social Compositions"  where the main goal was to provide an understanding of the stances of the abortion-
related Facebook posts at the state level in the
US from May 4- June 30, 2022, right after the
Supreme Court’s decision was disclosed. 

2. Who created the dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)?
Dataset was created by the research paper authors: Ana Aleksandric, Henry Isaac Anderson, Anisha Dangal, Gabriela Mustata Wilson, and Shirin Nilizadeh, on behalf of the University of Texas at Arlington.

3. Who funded the creation of the dataset?
No funding was used for this project.

4. Any other comments? 
None.

5. What do the instances that comprise the dataset represent (e.g.,
documents, photos, people, countries)? 
Dataset consists of unique IDs of Facebook pages and groups in the dataset that have to be supplemented to CrowdTangle API with the appropriate keyword, timeframe, and state to replicate the dataset.

6. How many instances are there in total (of each type, if appropriate)?
There are 13946 unique Page IDs and 2823 unique Group IDs.

7. Does the dataset contain all possible instances or is it a sample
(not necessarily random) of instances from a larger set?
It contains all the IDs of groups and pages used in the whole dataset.

8. What data does each instance consist of?
No other information is supplemented in the shared dataset except the unique IDs. In order to obtain the rest of the metadata, researchers have to use CrowdTangle.

9. Is there a label or target associated with each instance?
No.

10. Is any information missing from individual instances? 
No.

11.  Are relationships between individual instances made explicit
(e.g., users’ movie ratings, social network links)?
There are no relationships between different pages/groups.

12. Are there recommended data splits (e.g., training, development/validation,
testing)?
No, there are not.

13.  Are there any errors, sources of noise, or redundancies in the
dataset?
No, there are not.

14. Is the dataset self-contained, or does it link to or otherwise rely on
external resources (e.g., websites, tweets, other datasets)? 
Yes, each ID is a unique page/group that might not necessarily exist in the future. Therefore, such posts might not be obtainable. In addition, access to CrowdTangle API is restricted to academia only.

15. Does the dataset contain data that might be considered confidential (e.g., data that is protected by legal privilege or by doctor–
patient confidentiality, data that includes the content of individuals’ non-public communications)?
No.

16. Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety?
If the whole dataset is obtained, there might be some posts that cause anxiety if viewed directly.

17. Does the dataset identify any subpopulations (e.g., by age, gender)? I
No.

18. Is it possible to identify individuals (i.e., one or more natural persons), either directly or indirectly (i.e., in combination with other
data) from the dataset? 
If the whole dataset is extracted, it is possible to identify users who share posts in public groups. However, no identifiable information can be found in the CrowdTangle metadata.

19. Does the dataset contain data that might be considered sensitive
in any way (e.g., data that reveals race or ethnic origins, sexual orientations, religious beliefs, political opinions or union memberships, or locations; financial or health data; biometric or genetic
data; forms of government identification, such as social security
numbers; criminal history)? I
Some of the examples provided might be visible from users' profiles. However, such information is not present in the metadata itself.

20. How was the data associated with each instance acquired?
The data is observable (it is coming from Facebook).

21. What mechanisms or procedures were used to collect the data
(e.g., hardware apparatuses or sensors, manual human curation,
software programs, software APIs)? 
CrowdTangle API was used to collect data.

22. If the dataset is a sample from a larger set, what was the sampling
strategy (e.g., deterministic, probabilistic with specific sampling
probabilities)?
The dataset is not a part of a larger dataset.

23. Who was involved in the data collection process (e.g., students,
crowdworkers, contractors) and how were they compensated (e.g.,
how much were crowdworkers paid)?
Data was collected by paper authors. As stated above, no funding was provided for this project.

24. Over what timeframe was the data collected? 
May 4 to June 30, 2022.

25. Were any ethical review processes conducted (e.g., by an institutional review board)?
No.

26. Did you collect the data from the individuals in question directly,
or obtain it via third parties or other sources (e.g., websites)?
We used CrowdTangle API to obtain individual posts.

27. Did the individuals in question consent to the collection and use
of their data?
No, as the API is restricted to only sharing publicly available posts. 

28. Has an analysis of the potential impact of the dataset and its use
on data subjects (e.g., a data protection impact analysis) been conducted?
No.

29. Was any preprocessing/cleaning/labeling of the data done (e.g.,
discretization or bucketing, tokenization, part-of-speech tagging,
SIFT feature extraction, removal of instances, processing of missing values)?
We prepared and trained a RoBERTa and XLNet models on the text data. Also, we manually labeled the perceived gender of the users who shared posts in public groups.

30. Was the “raw” data saved in addition to the preprocessed/cleaned/labeled
data (e.g., to support unanticipated future uses)?
No, as we only share Page Group unique IDs.

31. Is the software that was used to preprocess/clean/label the data
available?
No.

32. Has the dataset been used for any tasks already?
We performed stance detection and statistical analysis described in the research paper.

33. Is there a repository that links to any or all papers or systems that
use the dataset?
Here is the pre-print of the paper: https://arxiv.org/abs/2305.09889

34. What (other) tasks could the dataset be used for?
The data can be used for multiple tasks, like analyzing sentiments or emotions of users toward abortion at the state level, as well as improving current state-of-the-art stance detection models.

35. Is there anything about the composition of the dataset or the way
it was collected and preprocessed/cleaned/labeled that might impact future uses?
No.

36. Are there tasks for which the dataset should not be used?
No.

37. Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which
the dataset was created?
No.

38. How will the dataset will be distributed (e.g., tarball on website,
API, GitHub)?
The dataset will be shared on Zenodo and GitHub.

39. When will the dataset be distributed?
The dataset is already published.

40. Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use
(ToU)?
The dataset is made public (Creative Commons Attribution 4.0 International).

41. Have any third parties imposed IP-based or other restrictions on
the data associated with the instances?
No.

42. Do any export controls or other regulatory restrictions apply to
the dataset or to individual instances? I
No.

43. Who will be supporting/hosting/maintaining the dataset
paper authors.

44. How can the owner/curator/manager of the dataset be contacted?
Via email, which can be found in the research paper.

45.Is there an erratum?
No.

46.Will the dataset be updated (e.g., to correct labeling errors, add
new instances, delete instances)?
No.

47. If the dataset relates to people, are there applicable limits on the
retention of the data associated with the instances (e.g., were the
individuals in question told that their data would be retained for
a fixed period of time and then deleted)?
No.

48. Will older versions of the dataset continue to be supported/hosted/maintained?
Currently, there are no other versions of the dataset.

49.If others want to extend/augment/build on/contribute to the
dataset, is there a mechanism for them to do so?
Other researchers can use the dataset for their research purposes.